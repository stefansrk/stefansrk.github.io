<!DOCTYPE html>
<html lang="en">
  <head>

        <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZJDHL99KDJ"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-ZJDHL99KDJ');
  </script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="Stefan Sarkadi" content="Stefan Sarkadi">
     <meta name="keywords" content="Stefan Sarkadi, Ștefan Sarkadi, artificial intelligence, deception, deceptive machines">


    <title>Stefan Sarkadi </title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">


    <!-- Custom styles for this template -->
    <link href="assets/css/main.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="assets/js/hover.zoom.js"></script>
    <script src="assets/js/hover.zoom.conf.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <!-- Static navbar -->
    <div class="navbar navbar-inverse navbar-static-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">Ștefan Sarkadi</a>
   <!--        <h2>"<i>History is a set of lies agreed upon.</i>" ~Napoleon Bonaparte</h2> -->

        </div>
        <div class="navbar-collapse collapse">
    <ul class="nav navbar-nav navbar-right">
      <li><a href="index.html">About Me</a></li>
      <li><a href="https://hide-lab.github.io/">HIDE Lab</a></li>
      <!-- <li><a href="research.html">Research</a></li> -->
      <li><a href="talks.html">Talks</a></li>
      <li><a href="papers.html">Publications</a></li>
      <li><a href="teaching.html">Teaching</a></li>
      <li><a href="people.html">People</a></li>
      <li><a href="CV_Sarkadi.pdf">CV</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>

	<!-- +++++ Welcome Section +++++ -->
	<div id="ww">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2 justified">




          <h5><img src="assets/img/story_AI.png" height="100" width=auto style="vertical-align:middle">Enhancing deception analysis with storytelling AI</h5>

          <p>Deception is becoming an increasingly complex socio-cognitive phenomenon that is difficult to detect and reason about. My research tackles the integration of techniques from AI and deception analysis to generate narratives about  interactions in complex and adaptive multi-agent systems in order to help intelligence analysts perform inference to the best explanation. To do this, I have recently been awarded a £200,000 fellowship grant by the Royal Academy of Engineering through the UK IC Postdoctoral Research Fellowship scheme for the project entitled <a href="https://raeng.org.uk/programmes-and-prizes/programmes/uk-grants-and-prizes/support-for-research/induction-awardees/dr-stefan-sarkadi-king-s-college-london">Enhancing deception analysis with storytelling AI</a>. This project is the continuation of my PhD thesis in AI entitled Deception.</p>



						<h5><img src="assets/img/decosystem.png" height="100" width=auto style="vertical-align:middle">Governing Knowledge-Sharing in Hybrid Societies</h5>

						<p> I am also involved in research projects related to knowledge sharing and privacy in hybrid systems. We are now in the age of <a href="https://dl.acm.org/doi/abs/10.1145/3571884.3603754" >deceptive AI ecosystems</a> where knowledge exchange has a significant role in how humans and machines adapt to each other. How do we ensure that hybrid societies, where humans and machines interact as agents will exchange knowledge in an honest, ethical, and sustainable manner? 

							To begin to answer this question, we must understand not only the <a href='https://kclpure.kcl.ac.uk/ws/portalfiles/portal/204173407/AAMAS_2023_Dishonest_AI_Study_9_.pdf'>ethics</a> of deceptive AI, but also how deception <a href='https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.201032'>evolves</a> in human-machine societies, and how societies <a href='https://dl.acm.org/doi/pdf/10.1145/3638549'>govern</a> themselves to become resilient in the face of deception. 

							Moreover, we must also look at how properties that were initially considered technical, such as the <a href='https://ieeexplore.ieee.org/abstract/document/9931915'>interoperability of Web agents</a>, are actually influenced by external evolutionary pressures of society such as financial incentives and businesses strategies at large. Subsequently, the evolution of human-machine relation might have ripple effects into the adoption of technology, putting various businesses at risk, such as agrirobotics.</p>




						<h5><img src="assets/img/portfolio/robot.png" height="100" width=auto style="vertical-align:middle">Deceptive AI</h5>




						<p>Autonomous agents might develop or be endowed with the ability to deceive. Deceptive machines first appear, more or less, as subtle concepts in Turing's famous <i>Imitation Game</i>. In this game, their role is to trick humans into assigning them the property of intelligence (and perhaps even the property of being phenomenally conscious?). Events that revolve around fake news indicate that humans are more susceptible than ever to mental manipulation by powerful technological tools. My concern is that, given future advancements in AI, these tools may become fully autonomous. This threat made me think that there might be several reasons for which we might consider modelling such agents. Now, the big question that follows from this is "How do we model these artificial agents in a manner such that we increase our understanding of them, instead of increasing the risks they might pose?". With this question in mind, in my <a
						href="https://kclpure.kcl.ac.uk/portal/en/theses/deception(472436d1-6edc-4958-85c5-0941ac948189).html">	PhD thesis </a>, I give the first full computational treatment to deception in AI. However, if you're not into reading PhD theses, you can have a look at my paper in IEEE Technology and Society to get a brief overview and history of the concept of  <a href="https://ieeexplore.ieee.org/document/10410131">deceptive AI</a></p>







								<p>To anyone interested in delving deeper into this topic, I recommend having a look at some of the symposia and workshops on deceptive AI (some of which I have co-organised): the <a href="https://sites.google.com/view/deceptecai2020">1st International Workshop on Deceptive AI @ECAI2020</a> and  the <a
									href="https://sites.google.com/view/deceptai2021"> 2nd International Workshop on Deceptive AI @IJCAI2021 </a>, the <a href="https://aaai.org/Press/Reports/Symposia/Fall/fs-15-03.php">2015 AAAI Fall Symposium on Deceptive and Counter-Deceptive Machines</a>, and the <a href="https://www.machinedeception.com/">2017 Deceptive Machines Workshop @NeurIPS</a>. Don't forget to check out the <a href="https://rd.springer.com/book/10.1007%2F978-3-030-91779-1">Deceptive AI Springer book</a> containing the joint proceedings of the two International Workshops on Deceptive AI.</p>

									<p style="text-align:center;"><a href="https://rd.springer.com/book/10.1007%2F978-3-030-91779-1"><img src="assets/img/proc.jpeg" alt="proceedings" height="400" width="300"></a></p>


						<h5><img src="assets/img/portfolio/tom.png" height="100" width=auto style="vertical-align:middle">Socially Reflective AI</h5>
					<p> Reflection, done right, could allow machines to reason and model the consequences of their actions in complex environments and together with the ability of using Theory of Mind, it enables them to model and reason about other agents' minds in these environments. Some of the scientific literature on this topic shows that Theory of Mind could increase the performance of artificial agents, making them more efficient than artificial agents that lack this ability. This includes making them more  <a href="https://content.iospress.com/articles/ai-communications/aic190615">effective at deceiving</a>.
					However, modelling others agents' minds is a difficult task, given that it involves many factors of uncertainty such as the uncertainty of the communication channel, the uncertainty of reading other agents correctly, and the uncertainty of trust in other agents. I am very fascinated by the promise of social AI and I am highly engaged this research topic, especially in the modelling of how artificial agents can cause changes in the beliefs of other agents through communication and how they <a href="https://arxiv.org/abs/2301.10823">reflect</a> on their own mental processes and selves. However, we must cautiously tread this path, as we could risk ending in an <a href="https://kclpure.kcl.ac.uk/portal/en/publications/an-arms-race-in-theory-of-mind-deception-drives-the-emergence-of-">arms race in Theory of Mind</a> between machines that deceive and machines that detect deception.</p>


						<!-- <h5><img src="assets/img/portfolio/ai.png" height="100" width=auto style="vertical-align:middle">Hybrid Societies</h5>
						<p>Checking how artifical agents behave in the lab or veryfying their reasoning with formal methods is crucial for the safe and ethical advancement of AI. However, neither of these approaches tells us much about how machines would act in the wild. By wild I mean complex hybrid societies where agents (human or artificial) interact. In this <a href="https://www.nature.com/articles/s41586-019-1138-y"> article</a>, the authors outline some questions that I believe are becoming more pertinent, namely: "Should the study of AI behaviour and reasoning be strictly limited to Computer Science?". Hence, are there any other methods to study and categorise the behaviour of artificial agents? How should we design these methods and what should they take into consideration about machines? Should we apply the same psychometrics to machines as we do to humans, or do we have to think about them in an entirely new way? </p> -->


						<h5><img src="assets/img/portfolio/ohaai.png" height="100" width=auto style="vertical-align:middle">Explainable AI</h5>
					<p> How do machines to explain and justify their reasoning and decision making? Argumentation in AI is seeing an increased interest due to its potential in shedding light onto issues like Explainable AI. Apart from actively doing research on how machines can generate meaningful arguments during social interactions (mostly dialogues), I have also worked together with my some of my PhD colleagues at King's to co-found the Online Handbook of Argumentation for AI. The purpose of this handbook is to provide an open access and curated anthology for the argumentation research community. <a href="https://ohaai.github.io/">OHAAI</a> will act as a research hub to keep track of the latest and upcoming topics and applications of argumentation in AI. The handbook mainly aims to present argumentation research conducted by current PhD students and early-career researchers in all areas where argumentation can be applied to AI. The handbook’s ulterior goal is to encourage collaboration and knowledge discovery between members of the argumentation community. As of 2022, OHAAI has become part of the COMMA conference. Students who submit extended abstracts to OHAAI have the opportunity to present their work at the <a href='https://ssa22.cs.cf.ac.uk/'>COMMA Summer School on Argumentation</a>.</p>




				</div><!-- /col-lg-8 -->
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /ww -->



	<!-- +++++ Footer Section +++++ -->

	<div id="footer">
		<div class="container">
			<div class="row">
				<div class="col-lg-4">
					<h4>Contact</h4>
					<p>
						email: <a>stefan.sarkadi [at] kcl.ac.uk</a><br/>
						<!-- email: <a>stefan.sarkadi [at] inria.fr</a><br/> -->
						or <a>stefan.sarkadi [at] inria.fr</a>
					</p>
				</div><!-- /col-lg-4 -->

				<div class="col-lg-4">
					<h4>My Links</h4>
					<p>
						<a href="https://www.linkedin.com/in/stefan-sarkadi-1902167a/">LinkedIn</a><br/>
						<a href="https://scholar.google.com/citations?user=6T30U-EAAAAJ&hl=en">Google Scholar Profile</a><br/>
						<!-- <a href="https://twitter.com/StefanSarkadi">Twitter</a><br/> -->

					</p>
				</div><!-- /col-lg-4 -->

				<div class="col-lg-4">
					<h4>About</h4>
					<p>&copy; Ștefan Sarkadi</p>
				</div><!-- /col-lg-4 -->

			</div>

		</div>
	</div>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.min.js"></script>
  </body>
</html>
