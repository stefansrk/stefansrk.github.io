<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="Stefan Sarkadi" content="Stefan Sarkadi">
     <meta name="keywords" content="Stefan Sarkadi, Ștefan Sarkadi, artificial intelligence, deception, deceptive machines">


    <title>Stefan Sarkadi </title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">


    <!-- Custom styles for this template -->
    <link href="assets/css/main.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="assets/js/hover.zoom.js"></script>
    <script src="assets/js/hover.zoom.conf.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <!-- Static navbar -->
    <div class="navbar navbar-inverse navbar-static-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">Ștefan Sarkadi</a>
   <!--        <h2>"<i>History is a set of lies agreed upon.</i>" ~Napoleon Bonaparte</h2> -->

        </div>
        <div class="navbar-collapse collapse">
    <ul class="nav navbar-nav navbar-right">
         <li><a href="index.html">About Me</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="talks.html">Talks</a></li>
            <li><a href="papers.html">Publications</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="people.html">People</a></li>
            <li><a href="CV_Sarkadi.pdf">CV</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>

	<!-- +++++ Welcome Section +++++ -->
	<div id="ww">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2 justified">




          <h5><img src="assets/img/story_AI.png" height="100" width=auto style="vertical-align:middle">Enhancing deception analysis with storytelling AI</h5>

          <p>Deception is becoming an increasingly complex socio-cognitive phenomenon that is difficult to detect and reason about. My research tackles the integration of techniques from AI and deception analysis to generate narratives about multi-agent interactions in complex systems in order to help intelligence analysts perform inference to the best explanation. To do this, I have recently been awarded a £200,000 fellowship grant by the Royal Academy of Engineering through the UK IC Postdoctoral Research Fellowship scheme for the project entitled <a href="https://raeng.org.uk/programmes-and-prizes/programmes/uk-grants-and-prizes/support-for-research/induction-awardees/dr-stefan-sarkadi-king-s-college-london">Enhancing deception analysis with storytelling AI</a>. This project is the continuation of his PhD thesis entitled Deception.</p>



						<h5><img src="assets/img/networkold2.png" height="100" width=auto style="vertical-align:middle">Governing Knowledge-Sharing in Hybrid Societies</h5>

						<p> I am also involved in research projects related to knowledge sharing and privacy in hybrid systems. The first project is the <a href="https://www.rephrain.ac.uk/praise/" >PRAISE</a> project with Jose Such and Natalia Criado at KCL within the UK-wide REPHRAIN Centre. The second is my 3IA Côte d’Azur Project with Fabien Gandon. This project is about designing and testing multi-agent models and protocols to orchestrate the interactions between agents that are powered by different AI technologies. The aim of this project is to ensure optimized collaborations between AI agents that augment, improve, and govern knowledge sharing activities in Multi-Agent Systems. The third project is within the international Hyper-Agents Project where I contribute towards the project's overarching agenda of defining a new class of Multi-Agent Systems that use hypermedia as a general mechanism for uniform interaction. The aim of this general mechanism is to support AI interoperability and traceability in complex interconnected systems.</p>




						<h5><img src="assets/img/portfolio/robot.png" height="100" width=auto style="vertical-align:middle">Deceptive AI</h5>




						<p>Autonomous agents might develop or be endowed with the ability to deceive. Deceptive machines first appear, more or less, as subtle concepts in Turing's famous <i>Imitation Game</i>. In this game, their role is to trick humans into assigning them the property of intelligence (and perhaps even the property of being phenomenally conscious?). Events that revolve around fake news indicate that humans are more susceptible than ever to mental manipulation by powerful technological tools. My concern is that, given future advancements in AI, these tools may become fully autonomous. This threat made me think that there might be several reasons for which we might consider modelling such agents. Now, the big question that follows from this is "How do we model these artificial agents in a manner such that we increase our understanding of them, instead of increasing the risks they might pose?". With this question in mind, in my <a
						href="https://kclpure.kcl.ac.uk/portal/en/theses/deception(472436d1-6edc-4958-85c5-0941ac948189).html">	PhD thesis </a>, I give the first full computational treatment to deception in AI. </p>







								<p>To anyone interested in this topic, I recommend having a look at some of the symposia and workshops on deceptive AI (some of which I have co-organised): the <a href="https://sites.google.com/view/deceptecai2020">1st International Workshop on Deceptive AI @ECAI2020</a> and  the <a
									href="https://sites.google.com/view/deceptai2021"> 2nd International Workshop on Deceptive AI @IJCAI2021 </a>, the <a href="https://aaai.org/Press/Reports/Symposia/Fall/fs-15-03.php">2015 AAAI Fall Symposium on Deceptive and Counter-Deceptive Machines</a>, and the <a href="https://www.machinedeception.com/">2017 Deceptive Machines Workshop @NeurIPS</a>. Don't forget to check out the <a href="https://rd.springer.com/book/10.1007%2F978-3-030-91779-1">Deceptive AI Springer book</a> containing the joint proceedings of the two International Workshops on Deceptive AI.</p>

									<p style="text-align:center;"><a href="https://rd.springer.com/book/10.1007%2F978-3-030-91779-1"><img src="assets/img/proc.jpeg" alt="proceedings" height="400" width="300"></a></p>


						<h5><img src="assets/img/portfolio/tom.png" height="100" width=auto style="vertical-align:middle">Socially-Aware AI</h5>
					<p> Artificial Theory of Mind enables machines to model and reason about other agents' minds. Some of the scientific literature on this topic shows that this ability could increase the performance of artificial agents, making them more efficient than artificial agents that lack this ability (<a href="https://link.springer.com/article/10.1007/s10458-015-9317-1">here is a very nice article about it</a>).
					However, modelling others agents' minds is a difficult task, given that it involves many factors of uncertainty such as the uncertainty of the communication channel, the uncertainty of reading other agents correctly, and the uncertainty of trust in other agents. I am very fascinated by the promise of social AI and I am highly engaged this research topic, especially in the modelling of how artificial agents can cause changes in the beliefs of other agents through communication. </p>


						<h5><img src="assets/img/portfolio/ai.png" height="100" width=auto style="vertical-align:middle">Machine Behaviour</h5>
						<p>Checking how artifical agents behave in the lab or veryfying their reasoning with formal methods is crucial for the safe and ethical advancement of AI. However, neither of these approaches tells us much about how machines would act in the wild. By wild I mean complex hybrid societies where agents (human or artificial) interact. In this <a href="https://www.nature.com/articles/s41586-019-1138-y"> article</a>, the authors outline some questions that I believe are becoming more pertinent, namely: "Should the study of AI behaviour and reasoning be strictly limited to Computer Science?". Hence, are there any other methods to study and categorise the behaviour of artificial agents? How should we design these methods and what should they take into consideration about machines? Should we apply the same psychometrics to machines as we do to humans, or do we have to think about them in an entirely new way? </p>


						<h5><img src="assets/img/portfolio/ohaai.png" height="100" width=auto style="vertical-align:middle">Explainable AI through Argumentation</h5>
					<p> How do machines to explain and justify their reasoning and decision making? Argumentation in AI is seeing an increased interest due to its potential in shedding light onto issues like Explainable AI. Apart from actively doing research on how machines can generate meaningful arguments during social interactions (mostly dialogues), I have also worked together with my some of my PhD colleagues at King's to co-found the Online Handbook of Argumentation for AI. The purpose of this handbook is to provide an open access and curated anthology for the argumentation research community. <a href="https://ohaai.github.io/">OHAAI</a> will act as a research hub to keep track of the latest and upcoming topics and applications of argumentation in AI. The handbook mainly aims to present argumentation research conducted by current PhD students and early-career researchers in all areas where argumentation can be applied to AI. The handbook’s ulterior goal is to encourage collaboration and knowledge discovery between members of the argumentation community. As of 2022, OHAAI has become part of the COMMA conference. Students who submit extended abstracts to OHAAI have the opportunity to present their work at the <a href='https://ssa22.cs.cf.ac.uk/'>COMMA Summer School on Argumentation</a>.</p>




				</div><!-- /col-lg-8 -->
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /ww -->



	<!-- +++++ Footer Section +++++ -->

	<div id="footer">
		<div class="container">
			<div class="row">
				<div class="col-lg-4">
					<h4>Contact</h4>
					<p>
						email: <a>stefan.sarkadi [at] inria.fr</a><br/>
						or <a>stefan.sarkadi [at] kcl.ac.uk</a>
					</p>
				</div><!-- /col-lg-4 -->

				<div class="col-lg-4">
					<h4>My Links</h4>
					<p>
						<a href="https://www.linkedin.com/in/stefan-sarkadi-1902167a/">LinkedIn</a><br/>
						<a href="https://scholar.google.com/citations?user=6T30U-EAAAAJ&hl=en">Google Scholar Profile</a><br/>
						<a href="https://twitter.com/StefanSarkadi">Twitter</a><br/>

					</p>
				</div><!-- /col-lg-4 -->

				<div class="col-lg-4">
					<h4>About</h4>
					<p>&copy; Ștefan Sarkadi</p>
				</div><!-- /col-lg-4 -->

			</div>

		</div>
	</div>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.min.js"></script>
  </body>
</html>
